@ARTICLE{5729374,
author={Weiming Hu and Nianhua Xie and Li Li and Xianglin Zeng and Maybank, S.},
journal={Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on},
title={A Survey on Visual Content-Based Video Indexing and Retrieval},
year={2011},
month={Nov},
volume={41},
number={6},
pages={797-819},
abstract={Video indexing and retrieval have a wide spectrum of promising applications, motivating the interest of researchers worldwide. This paper offers a tutorial and an overview of the landscape of general strategies in visual content-based video indexing and retrieval, focusing on methods for video structure analysis, including shot boundary detection, key frame extraction and scene segmentation, extraction of features including static key frame features, object features and motion features, video data mining, video annotation, video retrieval including query interfaces, similarity measure and relevance feedback, and video browsing. Finally, we analyze future research directions.},
keywords={feature extraction;indexing;multimedia computing;video retrieval;feature extraction;key frame extraction;motion features;multimedia information indexing;object features;query interfaces;relevance feedback;scene segmentation;shot boundary detection;static key frame features;video annotation;video browsing;video data mining;video structure analysis;visual content based video indexing;visual content based video retrieval;Clustering algorithms;Content based retrieval;Data mining;Feature extraction;Indexing;Visualization;Feature extraction;video annotation;video browsing;video retrieval;video structure analysis},
doi={10.1109/TSMCC.2011.2109710},
ISSN={1094-6977}
}

@ARTICLE{5986511,
author={Jian Lu and Xian-Sheng Hua and Dong Xu},
journal={MultiMedia, IEEE},
title={Visual Content Identification and Search},
year={2011},
month={March},
volume={18},
number={3},
pages={8-10},
abstract={The past few years have witnessed rapid development and commercialization of visual content identification and search technologies that are concerned with identifying and searching visual content, particularly image and video content, by visual similarities. This special issue contains several research articles covering a diverse range of topics in visual content identification and search.},
keywords={image retrieval;video signal processing;image content;video content;visual content identification;visual content search technology;visual similarities;Content management;Data visualization;Information retrieval;Search engines;Special issues and sections;IEEE MultiMedia;content identification;content-based copy detection;content-based image retrieval;content-based video retrieval;multimedia and graphics;visual search},
doi={10.1109/MMUL.2011.52},
ISSN={1070-986X}
}

@ARTICLE{5505997,
author={Zheng Cao and Ming Zhu},
journal={Consumer Electronics, IEEE Transactions on},
title={An efficient video similarity search algorithm},
year={2010},
month={May},
volume={56},
number={2},
pages={751-755},
abstract={For the convenience of content-based video retrieval in large storage device, a new efficient video similarity search approach is proposed in this paper. To solve two challenging problems: similarity measurement and search method, a novel video feature computation of image characteristic code was proposed based on spatial-temporal distribution of video frame sequences. The video similarity is measured based on the calculation of the number of similar video components. For the scalable computing requirement, a new search method according to clustering index table was presented by index clustering. The experimental results in large database query tests show this method is efficient and effective for similar video search.},
keywords={Content based retrieval;Density measurement;Distributed computing;Feature extraction;Image databases;Indexing;Search methods;Spatial databases;Variable structure systems;Video sharing;Video similarity search, Image characteristic code, Clustering index table, Spatial-temporal Distribution},
doi={10.1109/TCE.2010.5505997},
ISSN={0098-3063}
}

@ARTICLE{6775275,
author={Baroffio, L. and Cesana, M. and Redondi, A. and Tagliasacchi, M. and Tubaro, S.},
journal={Image Processing, IEEE Transactions on},
title={Coding Visual Features Extracted From Video Sequences},
year={2014},
month={May},
volume={23},
number={5},
pages={2262-2276},
abstract={Visual features are successfully exploited in several applications (e.g., visual search, object recognition and tracking, etc.) due to their ability to efficiently represent image content. Several visual analysis tasks require features to be transmitted over a bandwidth-limited network, thus calling for coding techniques to reduce the required bit budget, while attaining a target level of efficiency. In this paper, we propose, for the first time, a coding architecture designed for local features (e.g., SIFT, SURF) extracted from video sequences. To achieve high coding efficiency, we exploit both spatial and temporal redundancy by means of intraframe and interframe coding modes. In addition, we propose a coding mode decision based on rate-distortion optimization. The proposed coding scheme can be conveniently adopted to implement the analyze-then-compress (ATC) paradigm in the context of visual sensor networks. That is, sets of visual features are extracted from video frames, encoded at remote nodes, and finally transmitted to a central controller that performs visual analysis. This is in contrast to the traditional compress-then-analyze (CTA) paradigm, in which video sequences acquired at a node are compressed and then sent to a central unit for further processing. In this paper, we compare these coding paradigms using metrics that are routinely adopted to evaluate the suitability of visual features in the context of content-based retrieval, object recognition, and tracking. Experimental results demonstrate that, thanks to the significant coding gains achieved by the proposed coding scheme, ATC outperforms CTA with respect to all evaluation metrics.},
keywords={feature extraction;image representation;image retrieval;image sequences;object tracking;video coding;ATC;CTA paradigm;analyze then compress;bandwidth limited network;coding architecture;coding techniques;coding visual feature extraction;compress-then-analyze;content based retrieval;evaluation metrics;image content representation;interframe coding modes;object recognition;object tracking;rate distortion optimization;remote nodes;video frame extraction;video sequences;visual analysis;visual features;visual search;visual sensor networks;Encoding;Feature extraction;Image coding;Vectors;Video coding;Video sequences;Visualization;SIFT;SURF;Visual features;local descriptors;video coding},
doi={10.1109/TIP.2014.2312617},
ISSN={1057-7149}
}

